{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DistilBERT Fine-Tuning for Sentiment Analysis\n",
    "\n",
    "Fine-tuning DistilBERT for sentiment classification on airline reviews. The implementation addresses class imbalance through custom loss functions and ensures reproducibility with deterministic seeding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment & Configuration\n",
    "\n",
    "Setting up the necessary libraries and configuring the hardware environment.\n",
    "\n",
    "> [!NOTE]\n",
    "> **Reproducibility**: The `CUBLAS_WORKSPACE_CONFIG` is explicitly set and deterministic algorithms are enabled in PyTorch. To ensuring experiments are repeatable and not subject to hardware non-determinism.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:45:34.671022Z",
     "iopub.status.busy": "2025-08-05T01:45:34.670812Z",
     "iopub.status.idle": "2025-08-05T01:46:01.547127Z",
     "shell.execute_reply": "2025-08-05T01:46:01.546537Z",
     "shell.execute_reply.started": "2025-08-05T01:45:34.671005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-05 01:45:46.025214: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754358346.362409      84 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754358346.465729      84 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "# For CUDA determinism\n",
    "import os\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  \n",
    "\n",
    "# Force deterministic ops\n",
    "import torch\n",
    "torch.use_deterministic_algorithms(True, warn_only=True)  \n",
    "\n",
    "from transformers import set_seed as hf_set_seed \n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def set_seed(seed_value=12):\n",
    "    \"\"\"Fully deterministic seed setting\"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    hf_set_seed(seed_value)  \n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Initialize & Set SEED \n",
    "SEED = 12\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:01.980257Z",
     "iopub.status.busy": "2025-08-05T01:46:01.979886Z",
     "iopub.status.idle": "2025-08-05T01:46:14.855877Z",
     "shell.execute_reply": "2025-08-05T01:46:14.855174Z",
     "shell.execute_reply.started": "2025-08-05T01:46:01.980239Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Core\n",
    "import pandas as pd\n",
    "\n",
    "# PyTorch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn utilities\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Hugging Face ecosystem\n",
    "import evaluate\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    EarlyStoppingCallback,\n",
    "    pipeline\n",
    "    )\n",
    "\n",
    "# Experiment tracking\n",
    "import wandb\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "# Configure device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load Weights & Biases API key\n",
    "user_secrets = UserSecretsClient()\n",
    "secret_value_0 = user_secrets.get_secret(\"wandb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion & Analysis\n",
    "\n",
    "Loading the raw dataset and performing a preliminary inspection.\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> **Strategic Insight**: Analyzing the class distribution early informs the modeling strategy. Identifying skewness here allows for proactive design of the loss function to handle class imbalance later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:15.012360Z",
     "iopub.status.busy": "2025-08-05T01:46:15.012161Z",
     "iopub.status.idle": "2025-08-05T01:46:15.303010Z",
     "shell.execute_reply": "2025-08-05T01:46:15.302263Z",
     "shell.execute_reply.started": "2025-08-05T01:46:15.012344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/kaggle/input/sg-data0-85/0.85_labeled__dataset.csv')\n",
    "label2id = {'positive': 0,'negative': 1, 'mixed sentiment': 2}\n",
    "id2label = {0: \"positive\", 1: \"negative\", 2: \"mixed sentiment\"}\n",
    "\n",
    "data['label'] = data['final_sentiment'].map(label2id)\n",
    "\n",
    "df = data[['Text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:15.304107Z",
     "iopub.status.busy": "2025-08-05T01:46:15.303888Z",
     "iopub.status.idle": "2025-08-05T01:46:15.328199Z",
     "shell.execute_reply": "2025-08-05T01:46:15.327508Z",
     "shell.execute_reply.started": "2025-08-05T01:46:15.304089Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ok. We used this airline to go from Singapore ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The service in Suites Class makes one feel lik...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>don't give them your money. Booked, paid and r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Best Airline in the World. Best airline in the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  label\n",
       "0  Ok. We used this airline to go from Singapore ...      2\n",
       "1  The service in Suites Class makes one feel lik...      2\n",
       "2  don't give them your money. Booked, paid and r...      1\n",
       "3  Best Airline in the World. Best airline in the...      0\n",
       "4  Premium Economy Seating on Singapore Airlines ...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    6070\n",
       "1    2412\n",
       "2    1518\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.head(),df.value_counts('label'), df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization\n",
    "\n",
    "Initializing the `distilbert-base-uncased` architecture.\n",
    "\n",
    "> [!TIP]\n",
    "> **Why DistilBERT?** DistilBERT was chosen for its efficiency-performance trade-off. It retains 97% of BERT's performance while being 40% lighter and 60% faster, making it ideal for production environments where inference latency is a constraint.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custome Matric \n",
    "To properly evaluate the model, I implemented a custom compute_metrics function that calculates a comprehensive suite of metrics during training.\n",
    "\n",
    "This includes macro-averaged F1, weighted F1, and per-class F1 scores, allowing the training process to surface strengths and weaknesses across all labels rather than inflating performance due to dominant classes. Importantly, the function extracts the F1 score specifically for the mixed sentiment class, which served as a key indicator of whether Focal Loss and class weighting were improving performance where it mattered most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:15.352057Z",
     "iopub.status.busy": "2025-08-05T01:46:15.351771Z",
     "iopub.status.idle": "2025-08-05T01:46:16.485949Z",
     "shell.execute_reply": "2025-08-05T01:46:16.485473Z",
     "shell.execute_reply.started": "2025-08-05T01:46:15.352038Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df4658375de4b8d950a36b0b2156f84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30c660f332ec4bc9a5105cf282a73555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = evaluate.load(\"accuracy\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)['accuracy']\n",
    "    f1_macro_score = f1.compute(predictions=predictions, references=labels, average='macro')['f1']\n",
    "    f1_weighted_score = f1.compute(predictions=predictions, references=labels, average='weighted')['f1']\n",
    "    f1_per_class = f1.compute(predictions=predictions, references=labels, average=None)['f1']\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"f1_macro\": f1_macro_score,\n",
    "        \"f1_weighted\": f1_weighted_score,\n",
    "         \"f1_mixed\": f1_per_class[2]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:16.486845Z",
     "iopub.status.busy": "2025-08-05T01:46:16.486644Z",
     "iopub.status.idle": "2025-08-05T01:46:20.777936Z",
     "shell.execute_reply": "2025-08-05T01:46:20.776894Z",
     "shell.execute_reply.started": "2025-08-05T01:46:16.486828Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc51c92bee848f08dbe1413d9c346e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f639b67191b44b780382621ac18afd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f044915958cb4af9a8cf3607ac34697c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e56d44eff248cebce57880e33f4ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd3fdf827b34a24a22a683ad7f8106f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Setup Tokenizer & Model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path = model_name, use_fast = True)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=3, \n",
    "    id2label=id2label, \n",
    "    label2id=label2id\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing Pipeline\n",
    "\n",
    "The data is split into training, validation, and test sets to ensure robust evaluation. Text is then tokenized and class weights are calculated.\n",
    "\n",
    "> [!IMPORTANT]\n",
    "> **Handling Imbalance**: To counteract the imbalance observed in the EDA phase, class weights are computed and injected into the custom loss function to penalize the model more for misclassifying minority classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:20.779076Z",
     "iopub.status.busy": "2025-08-05T01:46:20.778833Z",
     "iopub.status.idle": "2025-08-05T01:46:20.797473Z",
     "shell.execute_reply": "2025-08-05T01:46:20.796704Z",
     "shell.execute_reply.started": "2025-08-05T01:46:20.779057Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7200, 2), (800, 2), (2000, 2))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 80/10/10 split, val split from train\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, stratify=train_df['label'], random_state=42)\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:20.798574Z",
     "iopub.status.busy": "2025-08-05T01:46:20.798349Z",
     "iopub.status.idle": "2025-08-05T01:46:20.868912Z",
     "shell.execute_reply": "2025-08-05T01:46:20.868352Z",
     "shell.execute_reply.started": "2025-08-05T01:46:20.798557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_df.reset_index(drop=True))\n",
    "val_dataset = Dataset.from_pandas(val_df.reset_index(drop=True))\n",
    "test_dataset = Dataset.from_pandas(test_df.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:20.869910Z",
     "iopub.status.busy": "2025-08-05T01:46:20.869632Z",
     "iopub.status.idle": "2025-08-05T01:46:24.294397Z",
     "shell.execute_reply": "2025-08-05T01:46:24.293772Z",
     "shell.execute_reply.started": "2025-08-05T01:46:20.869885Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6f323bcf1d4375bed5d446fce3b18d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60b80a7e64184ae299ad3f5c9f328075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/800 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98f936f254a48d2817211a7ba14ff99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"Text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True, num_proc=1)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True, num_proc=1)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True, num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:24.295216Z",
     "iopub.status.busy": "2025-08-05T01:46:24.295028Z",
     "iopub.status.idle": "2025-08-05T01:46:27.413074Z",
     "shell.execute_reply": "2025-08-05T01:46:27.412459Z",
     "shell.execute_reply.started": "2025-08-05T01:46:24.295200Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: tensor([0.5492, 1.3817, 2.1958], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Class Weight\n",
    "train_labels = train_dataset[:]['label']\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "#boost= 1.5\n",
    "#class_weights[2] = class_weights[2]*boost\n",
    "#print(class_weights)\n",
    "weights_tensor = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "print(\"Class Weights:\", weights_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:27.414014Z",
     "iopub.status.busy": "2025-08-05T01:46:27.413791Z",
     "iopub.status.idle": "2025-08-05T01:46:27.420898Z",
     "shell.execute_reply": "2025-08-05T01:46:27.420198Z",
     "shell.execute_reply.started": "2025-08-05T01:46:27.413996Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset = val_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset = test_dataset.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration\n",
    "\n",
    "Defining the hyperparameters and training arguments. The setup utilizes `bf16` precision for optimized performance on modern GPUs (T4/A100) and a `cosine` learning rate scheduler for better convergence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!TIP]\n",
    "> **ðŸ’¡ Custom Loss Function**: The trainer implements Focal Loss with weighted cross-entropy to handle class imbalance and focus on hard-to-classify examples. Implementation details below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:27.422201Z",
     "iopub.status.busy": "2025-08-05T01:46:27.421755Z",
     "iopub.status.idle": "2025-08-05T01:46:27.476103Z",
     "shell.execute_reply": "2025-08-05T01:46:27.475424Z",
     "shell.execute_reply.started": "2025-08-05T01:46:27.422176Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Used weights_tensor for weighted loss\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=weights_tensor)\n",
    "        loss = loss_fct(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "class CustomTrainerWithFocal(CustomTrainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Implimented Focal Loss \n",
    "        ce_loss = F.cross_entropy(logits, labels, weight=weights_tensor, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = ((1 - pt) ** 1.25 * ce_loss).mean()\n",
    "\n",
    "        return (focal_loss, outputs) if return_outputs else focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:27.476958Z",
     "iopub.status.busy": "2025-08-05T01:46:27.476792Z",
     "iopub.status.idle": "2025-08-05T01:46:40.268329Z",
     "shell.execute_reply": "2025-08-05T01:46:40.267715Z",
     "shell.execute_reply.started": "2025-08-05T01:46:27.476944Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvinilpatel-ai\u001b[0m (\u001b[33mvinilpatel-ai-personal\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20250805_014633-yvcn869m</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vinilpatel-ai-personal/SG_FineTune/runs/yvcn869m' target=\"_blank\">6_re-run12_v17_fl1.25_deploy</a></strong> to <a href='https://wandb.ai/vinilpatel-ai-personal/SG_FineTune' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vinilpatel-ai-personal/SG_FineTune' target=\"_blank\">https://wandb.ai/vinilpatel-ai-personal/SG_FineTune</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vinilpatel-ai-personal/SG_FineTune/runs/yvcn869m' target=\"_blank\">https://wandb.ai/vinilpatel-ai-personal/SG_FineTune/runs/yvcn869m</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vinilpatel-ai-personal/SG_FineTune/runs/yvcn869m?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7c18dadb8e50>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=secret_value_0)\n",
    "wandb.init(project=\"SG_FineTune\", name='6_re-run12_v17_fl1.25_deploy' ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:40.269164Z",
     "iopub.status.busy": "2025-08-05T01:46:40.268991Z",
     "iopub.status.idle": "2025-08-05T01:46:40.305259Z",
     "shell.execute_reply": "2025-08-05T01:46:40.304520Z",
     "shell.execute_reply.started": "2025-08-05T01:46:40.269149Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=model_dir,\n",
    "    num_train_epochs=3,                   # Slightly more training for refinement\n",
    "    per_device_train_batch_size=16,                   \n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=6e-5,                                \n",
    "    warmup_ratio=0.1,                    # Used ratio instead of fixed warmup steps\n",
    "    weight_decay=0.05,                      \n",
    "    bf16=True,                           # T4 supports bf16)\n",
    "    logging_dir=logging_dir,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"epoch\", \n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",  # For Class Wise balance\n",
    "    save_total_limit=2 ,\n",
    "    max_grad_norm=1.0,\n",
    "    lr_scheduler_type='cosine',\n",
    "    seed = SEED,\n",
    "    dataloader_num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:40.308367Z",
     "iopub.status.busy": "2025-08-05T01:46:40.308105Z",
     "iopub.status.idle": "2025-08-05T01:46:41.072356Z",
     "shell.execute_reply": "2025-08-05T01:46:41.070570Z",
     "shell.execute_reply.started": "2025-08-05T01:46:40.308349Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_84/184643347.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `CustomTrainerWithFocal.__init__`. Use `processing_class` instead.\n",
      "  trainer = CustomTrainerWithFocal(\n"
     ]
    }
   ],
   "source": [
    "trainer = CustomTrainerWithFocal(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,  # Custome Matric - Accuracy, F1 marco & Weighted\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Evaluation\n",
    "\n",
    "The model is trained on the training data and validated at the end of each epoch. Once training is complete, a final evaluation is run on the held-out test set to measure real-world performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:46:41.073912Z",
     "iopub.status.busy": "2025-08-05T01:46:41.073281Z",
     "iopub.status.idle": "2025-08-05T01:56:17.355750Z",
     "shell.execute_reply": "2025-08-05T01:56:17.354996Z",
     "shell.execute_reply.started": "2025-08-05T01:46:41.073881Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py:823: UserWarning: Memory Efficient attention defaults to a non-deterministic algorithm. To explicitly enable determinism call torch.use_deterministic_algorithms(True, warn_only=False). (Triggered internally at /pytorch/aten/src/ATen/native/transformers/cuda/attention_backward.cu:683.)\n",
      "  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='675' max='675' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [675/675 09:32, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>F1 Mixed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.243451</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.775305</td>\n",
       "      <td>0.826047</td>\n",
       "      <td>0.567335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.142000</td>\n",
       "      <td>0.254122</td>\n",
       "      <td>0.848750</td>\n",
       "      <td>0.804538</td>\n",
       "      <td>0.862038</td>\n",
       "      <td>0.618297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058600</td>\n",
       "      <td>0.304402</td>\n",
       "      <td>0.868750</td>\n",
       "      <td>0.814420</td>\n",
       "      <td>0.875144</td>\n",
       "      <td>0.625899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=675, training_loss=0.20620376997523837, metrics={'train_runtime': 575.8208, 'train_samples_per_second': 37.512, 'train_steps_per_second': 1.172, 'total_flos': 2861346838118400.0, 'train_loss': 0.20620376997523837, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:56:17.380878Z",
     "iopub.status.busy": "2025-08-05T01:56:17.380659Z",
     "iopub.status.idle": "2025-08-05T01:56:34.548657Z",
     "shell.execute_reply": "2025-08-05T01:56:34.548086Z",
     "shell.execute_reply.started": "2025-08-05T01:56:17.380861Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.2434888333082199,\n",
       " 'eval_accuracy': 0.8885,\n",
       " 'eval_f1_macro': 0.8464833523306581,\n",
       " 'eval_f1_weighted': 0.8944322055157344,\n",
       " 'eval_f1_mixed': 0.6827880512091038,\n",
       " 'eval_runtime': 17.1392,\n",
       " 'eval_samples_per_second': 116.692,\n",
       " 'eval_steps_per_second': 3.676,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:56:34.550075Z",
     "iopub.status.busy": "2025-08-05T01:56:34.549608Z",
     "iopub.status.idle": "2025-08-05T01:56:51.811765Z",
     "shell.execute_reply": "2025-08-05T01:56:51.811019Z",
     "shell.execute_reply.started": "2025-08-05T01:56:34.550055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       positive       0.97      0.91      0.94      1214\n",
      "       negative       0.95      0.89      0.92       482\n",
      "mixed sentiment       0.60      0.79      0.68       304\n",
      "\n",
      "       accuracy                           0.89      2000\n",
      "      macro avg       0.84      0.86      0.85      2000\n",
      "   weighted avg       0.91      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get predictions \n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "y_true = predictions.label_ids\n",
    "y_pred = predictions.predictions.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=label2id.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:56:51.812884Z",
     "iopub.status.busy": "2025-08-05T01:56:51.812606Z",
     "iopub.status.idle": "2025-08-05T01:56:51.817171Z",
     "shell.execute_reply": "2025-08-05T01:56:51.816412Z",
     "shell.execute_reply.started": "2025-08-05T01:56:51.812859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Publishing\n",
    "\n",
    "Finally, the trained model and tokenizer are pushed to the Hugging Face Hub, making the model accessible for inference and future deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T01:58:22.580452Z",
     "iopub.status.busy": "2025-08-05T01:58:22.579463Z",
     "iopub.status.idle": "2025-08-05T01:58:22.606557Z",
     "shell.execute_reply": "2025-08-05T01:58:22.605725Z",
     "shell.execute_reply.started": "2025-08-05T01:58:22.580415Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e908220fa66446babff6c7fc55d90a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-05T02:02:34.157992Z",
     "iopub.status.busy": "2025-08-05T02:02:34.157577Z",
     "iopub.status.idle": "2025-08-05T02:02:45.643485Z",
     "shell.execute_reply": "2025-08-05T02:02:45.642880Z",
     "shell.execute_reply.started": "2025-08-05T02:02:34.157971Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb27a1430d0c4d45a088ab8ab500f7e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9da264d46848389f0e5fe52e373b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Yoshaaa7/distilbert-SGairline-sentiment-private/commit/43d59982241506bdbc79c598b82de60c818d3708', commit_message='Upload tokenizer', commit_description='', oid='43d59982241506bdbc79c598b82de60c818d3708', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Yoshaaa7/distilbert-SGairline-sentiment-private', endpoint='https://huggingface.co', repo_type='model', repo_id='Yoshaaa7/distilbert-SGairline-sentiment-private'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_repo_id = \"Yoshaaa7/distilbert-SGairline-sentiment-private\"\n",
    "model.push_to_hub(distilbert_repo_id, private=True)\n",
    "tokenizer.push_to_hub(distilbert_repo_id, private=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results & Retrospective\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "The model achieved a weighted F1-score of **0.89**, which is strong for a 3-class problem.\n",
    "\n",
    "- **Positive/Negative**: The model is highly effective at distinguishing clear sentiment (F1 ~0.92-0.94)\n",
    "- **The Challenge of \"Mixed\"**: The \"Mixed Sentiment\" class was the hardest to predict (F1 ~0.68). This confirms the hypothesis that subtle, conflicting sentiments are difficult for the model to disentangle\n",
    "\n",
    "### Impact of Technical Decisions\n",
    "\n",
    "- **Focal Loss**: Implementing this was crucial. Without it, the model likely would have ignored the \"Mixed\" class entirely in favor of the majority classes\n",
    "- **Class Weights**: This ensured that the minority classes weren't drowned out during gradient updates\n",
    "\n",
    "### Tools & Skills\n",
    "\n",
    "- **Weights & Biases**: W&B was used to track experiments. Seeing the loss curves diverge early helped tune the learning rate\n",
    "- **Hugging Face**: Leveraging the `Trainer` API allowed focus on the custom loss logic rather than writing boilerplate training loops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7971919,
     "sourceId": 12618170,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
